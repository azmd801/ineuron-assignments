{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmd801/ineuron-assignments/blob/main/DL%20theory%20/Assignment_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14928b60",
      "metadata": {
        "id": "14928b60"
      },
      "source": [
        "1. Write the Python code to implement a single neuron."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e4ff1b",
      "metadata": {
        "id": "e0e4ff1b"
      },
      "source": [
        "2. Write the Python code to implement ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400db13c",
      "metadata": {
        "id": "400db13c"
      },
      "source": [
        "3. Write the Python code for a dense layer in terms of matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "186d2cae",
      "metadata": {
        "id": "186d2cae"
      },
      "source": [
        "4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335e78b1",
      "metadata": {
        "id": "335e78b1"
      },
      "source": [
        "5. What is the “hidden size” of a layer?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f61d7f",
      "metadata": {
        "id": "70f61d7f"
      },
      "source": [
        "6. What does the t method do in PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9c6a70",
      "metadata": {
        "id": "ac9c6a70"
      },
      "source": [
        "7. Why is matrix multiplication written in plain Python very slow?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f7b25a1",
      "metadata": {
        "id": "3f7b25a1"
      },
      "source": [
        "8. In matmul, why is ac==br?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5e39b8f",
      "metadata": {
        "id": "e5e39b8f"
      },
      "source": [
        "9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ee492f",
      "metadata": {
        "id": "b9ee492f"
      },
      "source": [
        "10. What is elementwise arithmetic?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7119be6c",
      "metadata": {
        "id": "7119be6c"
      },
      "source": [
        "11. Write the PyTorch code to test whether every element of a is greater than the corresponding element of b."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74192915",
      "metadata": {
        "id": "74192915"
      },
      "source": [
        "12. What is a rank-0 tensor? How do you convert it to a plain Python data type?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8010fc8",
      "metadata": {
        "id": "a8010fc8"
      },
      "source": [
        "13. How does elementwise arithmetic help us speed up matmul?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb2cd94",
      "metadata": {
        "id": "ccb2cd94"
      },
      "source": [
        "14. What are the broadcasting rules?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cdfd8c8",
      "metadata": {
        "id": "3cdfd8c8"
      },
      "source": [
        "15. What is expand_as? Show an example of how it can be used to match the results of broadcasting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5e3431",
      "metadata": {
        "id": "9d5e3431"
      },
      "source": [
        "1. Write the Python code to implement a single neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6954c4",
      "metadata": {
        "id": "dd6954c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "    def single_neuron(inputs, weights, bias, activation_function):\n",
        "        return activation_function(sum([x*w for x, w in zip(inputs, weights)]) + bias)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74ecfe8",
      "metadata": {
        "id": "a74ecfe8"
      },
      "source": [
        "2. Write the Python code to implement ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279acce6",
      "metadata": {
        "id": "279acce6"
      },
      "outputs": [],
      "source": [
        "\n",
        "    def relu(x):\n",
        "        return max(0, x)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d2af30",
      "metadata": {
        "id": "31d2af30"
      },
      "source": [
        "3. Write the Python code for a dense layer in terms of matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e7b41a",
      "metadata": {
        "id": "19e7b41a"
      },
      "outputs": [],
      "source": [
        "\n",
        "    import numpy as np\n",
        "\n",
        "    def dense_layer(inputs, weights, bias):\n",
        "        return np.dot(inputs, weights) + bias\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facdb8a7",
      "metadata": {
        "id": "facdb8a7"
      },
      "source": [
        "4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be8b032",
      "metadata": {
        "id": "6be8b032"
      },
      "outputs": [],
      "source": [
        "\n",
        "    def dense_layer_plain_python(inputs, weights, bias):\n",
        "        return [sum(x*w for x, w in zip(input, weight)) + b for input, weight, b in zip(inputs, weights, bias)]\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe35b3b2",
      "metadata": {
        "id": "fe35b3b2"
      },
      "source": [
        "5. What is the “hidden size” of a layer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6264a9de",
      "metadata": {
        "id": "6264a9de"
      },
      "outputs": [],
      "source": [
        "\n",
        "    The \"hidden size\" of a layer in a neural network refers to the number of neurons or units in that layer. It determines the dimensionality of the output of that layer.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d432cc",
      "metadata": {
        "id": "50d432cc"
      },
      "source": [
        "6. What does the t method do in PyTorch?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417ec8bc",
      "metadata": {
        "id": "417ec8bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "    In PyTorch, the `t` method is used to transpose a matrix. It is mainly used for 2D tensors. For tensors with more than two dimensions, it is recommended to use the `transpose` method.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "636c8391",
      "metadata": {
        "id": "636c8391"
      },
      "source": [
        "7. Why is matrix multiplication written in plain Python very slow?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8aa25dd",
      "metadata": {
        "id": "e8aa25dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "    Implementing matrix multiplication in plain Python is very slow compared to optimized libraries like NumPy or PyTorch because Python is a high-level, dynamically typed language. It involves more overhead during runtime, and it doesn't utilize optimizations like vectorized operations and multi-threading that are available in libraries like NumPy and PyTorch.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37cc7ffd",
      "metadata": {
        "id": "37cc7ffd"
      },
      "source": [
        "8. In matmul, why is ac==br?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78a6781",
      "metadata": {
        "id": "b78a6781"
      },
      "outputs": [],
      "source": [
        "\n",
        "    In matrix multiplication, the number of columns in the first matrix (`A`) must equal the number of rows in the second matrix (`B`). This condition is usually written as `A[m x n] * B[n x p] = C[m x p]`, where `n` is the common dimension. So, `ac == br` is checking to ensure that this condition is met, where `ac` is the number of columns in `A` and `br` is the number of rows in `B`.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e21c8c61",
      "metadata": {
        "id": "e21c8c61"
      },
      "source": [
        "9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f869bb",
      "metadata": {
        "id": "e0f869bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "    In a Jupyter Notebook, you can measure the time taken for a single cell to execute using the `%time` or `%timeit` magic commands. Here's how you can use them:\n",
        "\n",
        "    ```python\n",
        "    %time result = some_function()\n",
        "\n",
        "    %timeit result = some_function()\n",
        "    ```\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "823e98f3",
      "metadata": {
        "id": "823e98f3"
      },
      "source": [
        "10. What is elementwise arithmetic?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f92e422",
      "metadata": {
        "id": "8f92e422"
      },
      "outputs": [],
      "source": [
        "\n",
        "    Elementwise arithmetic refers to operations that are performed on corresponding elements of arrays or matrices. In Python, this can be done using libraries like NumPy, which supports elementwise operations such as addition, subtraction, multiplication, and division. These operations are performed on a element-by-element basis, rather than through matrix multiplication or other matrix operations.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e6cd95",
      "metadata": {
        "id": "30e6cd95"
      },
      "source": [
        "11. Write the PyTorch code to test whether every element of a is greater than the corresponding element of b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61eb58ee",
      "metadata": {
        "id": "61eb58ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "    In PyTorch, you can use the `torch.gt(a, b)` function to check if each element in tensor `a` is greater than the corresponding element in tensor `b`. Here's an example:\n",
        "\n",
        "    ```python\n",
        "    import torch\n",
        "\n",
        "    a = torch.tensor([1.0, 2.0, 3.0])\n",
        "    b = torch.tensor([0.5, 1.5, 2.5])\n",
        "\n",
        "    result = torch.gt(a, b)\n",
        "    print(result)\n",
        "    ```\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e852686a",
      "metadata": {
        "id": "e852686a"
      },
      "source": [
        "12. What is a rank-0 tensor? How do you convert it to a plain Python data type?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc40c4db",
      "metadata": {
        "id": "fc40c4db"
      },
      "outputs": [],
      "source": [
        "\n",
        "    A rank-0 tensor, also known as a scalar tensor, is a tensor that contains a single value. You can convert a rank-0 tensor to a plain Python data type using the `.item()` method. Here's an example:\n",
        "\n",
        "    ```python\n",
        "    import torch\n",
        "\n",
        "    scalar_tensor = torch.tensor(42.0)\n",
        "    python_scalar = scalar_tensor.item()\n",
        "\n",
        "    print(type(python_scalar))  # Output: <class 'float'>\n",
        "    ```\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365db2dd",
      "metadata": {
        "id": "365db2dd"
      },
      "source": [
        "13. How does elementwise arithmetic help us speed up matmul?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2861b663",
      "metadata": {
        "id": "2861b663"
      },
      "outputs": [],
      "source": [
        "\n",
        "    Elementwise arithmetic can speed up matrix multiplication (matmul) by allowing us to perform operations on entire arrays or matrices at once, rather than iterating over individual elements. This takes advantage of vectorized operations, which are highly optimized in libraries like NumPy and PyTorch, and can lead to significant performance improvements compared to plain Python implementations.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46436b45",
      "metadata": {
        "id": "46436b45"
      },
      "source": [
        "14. What are the broadcasting rules?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9ce7cb",
      "metadata": {
        "id": "ac9ce7cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "    Broadcasting is a technique used to perform operations on arrays of different shapes. The broadcasting rules in NumPy (and similarly in PyTorch) are as follows:\n",
        "\n",
        "    1. If the arrays do not have the same rank, prepend the shape of the lower rank array with ones until both shapes have the same length.\n",
        "    2. The sizes of the arrays in each dimension must either be the same or one of them must be one.\n",
        "    3. If the size of the arrays in a dimension is not the same, and one of the arrays has size 1 in that dimension, the array with size 1 is stretched to match the other size.\n",
        "\n",
        "    These rules allow you to perform elementwise operations on arrays of different shapes, as long as the shapes are compatible according to the rules.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3876feea",
      "metadata": {
        "id": "3876feea"
      },
      "source": [
        "15. What is expand_as? Show an example of how it can be used to match the results of broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eebd8a81",
      "metadata": {
        "id": "eebd8a81"
      },
      "outputs": [],
      "source": [
        "\n",
        "    The `expand_as` method in PyTorch is used to expand a tensor to have the same size as another tensor. This is often used in conjunction with broadcasting, to explicitly reshape a tensor before performing an operation. Here's an example:\n",
        "\n",
        "    ```python\n",
        "    import torch\n",
        "\n",
        "    a = torch.tensor([[1], [2]])\n",
        "    b = torch.tensor([[3, 4], [5, 6]])\n",
        "\n",
        "    # Using expand_as to match the size of b\n",
        "    a_expanded = a.expand_as(b)\n",
        "\n",
        "    # Now we can perform elementwise operations\n",
        "    result = a_expanded + b\n",
        "\n",
        "    print(result)\n",
        "    ```\n",
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}