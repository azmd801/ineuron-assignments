{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFFjMQOYbneknq1vPTic+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmd801/ineuron-assignments/blob/main/DL%20theory%20/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **What are the advantages of a CNN over a fully connected DNN for image classification?**\n",
        "\n",
        "   Convolutional Neural Networks (CNNs) offer several advantages over fully connected Deep Neural Networks (DNNs) for image classification:\n",
        "   \n",
        "   - **Local Connectivity:** CNNs exploit spatial hierarchies by connecting neurons only to local regions in the input.\n",
        "   - **Parameter Sharing:** Sharing weights within convolutional kernels reduces the number of parameters, aiding generalization.\n",
        "   - **Translation Invariance:** CNNs can detect features regardless of their location in the input.\n",
        "   - **Hierarchical Features:** Convolutional layers capture low-level features, which are combined into higher-level features.\n",
        "\n",
        "2. **Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels. What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?**\n",
        "\n",
        "   The calculation for the total number of parameters and RAM requirements can be complex, involving kernel size, input channels, output channels, and data types. To compute these values accurately, you would need to consider factors like bias terms and intermediate activations during training. However, as a simplified approach:\n",
        "\n",
        "   - **Total Parameters:** Roughly calculated by summing the weights and biases of each layer.\n",
        "   - **RAM for Inference:** Total RAM required includes model weights, intermediate activations, and input data.\n",
        "   - **RAM for Training:** Additional memory is required to store gradients and intermediate values during backpropagation.\n",
        "\n",
        "   Please consult the exact formulas for these calculations depending on your network configuration.\n",
        "\n",
        "3. **If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?**\n",
        "\n",
        "   - Reduce Batch Size: Smaller batches consume less memory.\n",
        "   - Reduce Model Size: Fewer parameters decrease memory usage.\n",
        "   - Use Mixed Precision: Float16 consumes less memory than float32.\n",
        "   - Free GPU Memory: Delete unused tensors and variables.\n",
        "   - Gradient Clipping: Limit gradients to prevent memory spikes.\n",
        "\n",
        "4. **Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?**\n",
        "\n",
        "   Max pooling layers downsample feature maps while retaining dominant features. They introduce translational invariance and reduce computation. Adding more convolutional layers with large strides would cause loss of fine-grained information.\n",
        "\n",
        "5. **When would you want to add a local response normalization layer?**\n",
        "\n",
        "   Local Response Normalization (LRN) layers were popularized by AlexNet. They were used to provide a form of lateral inhibition among neurons to enhance contrast in local feature maps. However, they are less commonly used now, as techniques like batch normalization have shown better results.\n",
        "\n",
        "6. **Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?**\n",
        "\n",
        "   - **AlexNet:** Introduced deeper architecture, ReLU activation, dropout, and GPU acceleration.\n",
        "   - **GoogLeNet:** Pioneered inception modules, efficient use of parameters, and introduced global average pooling.\n",
        "   - **ResNet:** Introduced residual connections, enabling training of very deep networks.\n",
        "   - **SENet:** Included squeeze-and-excitation blocks, enabling networks to focus on informative features.\n",
        "   - **Xception:** Applied depthwise separable convolutions for efficient and powerful feature extraction.\n",
        "\n",
        "7. **What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?**\n",
        "\n",
        "   A fully convolutional network (FCN) is a neural network architecture composed entirely of convolutional layers, allowing it to accept input of any size. A dense layer can be converted into a convolutional layer by replacing its weights with filters of the same shape, effectively applying a global filter to the entire input volume.\n",
        "\n",
        "8. **What is the main technical difficulty of semantic segmentation?**\n",
        "\n",
        "   The main difficulty in semantic segmentation is capturing accurate object boundaries and handling instances that are closely connected or overlap. Maintaining context while distinguishing objects and their boundaries requires intricate architectural designs and techniques like skip connections and dilated convolutions."
      ],
      "metadata": {
        "id": "Un3KB_ynmfoU"
      }
    }
  ]
}