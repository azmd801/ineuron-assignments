{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjlSNUXRN+z5hhZ2X86wjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmd801/ineuron-assignments/blob/main/DL%20theory/Assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
        "\n",
        "- **Sequence-to-Sequence RNN**:\n",
        "  - Machine Translation: Translating sentences from one language to another.\n",
        "  - Speech Recognition: Converting spoken language into written text.\n",
        "  - Video Captioning: Generating captions for videos.\n",
        "- **Sequence-to-Vector RNN**:\n",
        "  - Sentiment Analysis: Determining the sentiment of a text.\n",
        "  - Anomaly Detection: Identifying unusual patterns in time series data.\n",
        "- **Vector-to-Sequence RNN**:\n",
        "  - Image Captioning: Generating a series of words to describe an image.\n",
        "  - Music Generation: Creating a sequence of notes based on an initial seed.\n",
        "\n",
        "### 2. How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?\n",
        "\n",
        "The inputs to an RNN layer generally have three dimensions:\n",
        "- Batch size: The number of samples in a batch.\n",
        "- Time steps: The number of time steps in the sequence.\n",
        "- Features: The number of features at each time step.\n",
        "The output dimensions depend on the configuration of the RNN. It can be two-dimensional (batch size, features) for sequence-to-vector RNNs or three-dimensional (batch size, time steps, features) for sequence-to-sequence RNNs.\n",
        "\n",
        "### 3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should have `return_sequences=True`? What about a sequence-to-vector RNN?\n",
        "\n",
        "- **Deep Sequence-to-Sequence RNN**: All RNN layers except the last one should have `return_sequences=True` to allow the passing of sequences between layers.\n",
        "- **Sequence-to-Vector RNN**: Only the last layer will have `return_sequences=False` to output a vector.\n",
        "\n",
        "### 4. Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?\n",
        "\n",
        "For forecasting the next seven days in a daily univariate time series, a sequence-to-vector RNN can be used where the input sequence contains the features from the previous days and the output vector contains the forecasts for the next seven days.\n",
        "\n",
        "### 5. What are the main difficulties when training RNNs? How can you handle them?\n",
        "\n",
        "The main difficulties when training RNNs are:\n",
        "- Vanishing Gradients: Can be handled using techniques like gradient clipping or using activation functions like ReLU.\n",
        "- Exploding Gradients: Can be handled using gradient clipping or batch normalization.\n",
        "- Overfitting: Can be mitigated using techniques like dropout or early stopping.\n",
        "Handling these issues might involve using more complex RNN architectures like LSTMs or GRUs which are designed to mitigate the vanishing gradient problem.\n",
        "\n",
        "### 6. Can you sketch the LSTM cellâ€™s architecture?\n",
        "\n",
        "The LSTM cell's architecture consists of three gates (input, forget, and output gates) and a cell state. Here is a textual representation:\n",
        "- Input Gate: Controls the flow of input data into the cell state.\n",
        "- Forget Gate: Decides what information to discard from the cell state.\n",
        "- Cell State: Holds the long-term information.\n",
        "- Output Gate: Controls the output based on the cell state and the input.\n",
        "(Note: A visual sketch can be made using a diagram drawing tool or by embedding an image of an LSTM cell's architecture.)\n",
        "\n",
        "The LSTM cell's architecture consists of three gates: the input gate, the forget gate, and the output gate, along with a cell state. Here is a diagram illustrating the LSTM cell architecture:\n",
        "\n",
        "![LSTM Architecture](https://miro.medium.com/max/1400/1*laH0_xXEkFE0lKJu54gkFQ.png)\n",
        "\n",
        "Image Source: [Medium](https://miro.medium.com/max/1400/1*laH0_xXEkFE0lKJu54gkFQ.png)\n",
        "\n",
        "\n",
        "### 7. Why would you want to use 1D convolutional layers in an RNN?\n",
        "\n",
        "Using 1D convolutional layers in an RNN can help in:\n",
        "- Reducing the sequence length by applying pooling layers, which can help in reducing computation time.\n",
        "- Extracting local patterns or features within the sequence, which can potentially enhance the performance of the RNN.\n",
        "\n",
        "### 8. Which neural network architecture could you use to classify videos?\n",
        "\n",
        "To classify videos, a combination of Convolutional Neural Networks (CNNs) and RNNs can be used. The CNN extracts features from frames, and the RNN processes the sequence of extracted features to classify the video. Another popular approach is using 3D CNNs which can process the spatial and temporal dimensions simultaneously."
      ],
      "metadata": {
        "id": "E7l-HHwDsuD9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcXZbsgctB-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}